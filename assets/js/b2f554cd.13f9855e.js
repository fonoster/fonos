"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"Dialogflow entities","metadata":{"permalink":"/blog/Dialogflow entities","editUrl":"https://github.com/fonoster/website/edit/main/docs/blog/blog/2023_02_08-dialogflow_entities.md","source":"@site/blog/2023_02_08-dialogflow_entities.md","title":"Dialogflow entities. Capturing useful data.","description":"Dialogflow sits in the middle between the user and our application, helping us capture conversations from natural language into useful and readable data.","date":"2023-12-12T01:58:28.000Z","formattedDate":"December 12, 2023","tags":[{"label":"fonoster","permalink":"/blog/tags/fonoster"},{"label":"voice","permalink":"/blog/tags/voice"},{"label":"OSS","permalink":"/blog/tags/oss"},{"label":"VUI","permalink":"/blog/tags/vui"},{"label":"Dialogflow","permalink":"/blog/tags/dialogflow"}],"readingTime":2.085,"hasTruncateMarker":false,"authors":[{"name":"Yuri Santana","title":"Developer Relations Advocate at Fonoster","url":"https://github.com/yuricodes","imageURL":"https://github.com/yuricodes.png","key":"yuricodes"}],"frontMatter":{"slug":"Dialogflow entities","title":"Dialogflow entities. Capturing useful data.","authors":["yuricodes"],"tags":["fonoster","voice","OSS","VUI","Dialogflow"]},"nextItem":{"title":"Differences in types of Conversational Interfaces","permalink":"/blog/Differences in types of Conversational Interfaces"}},"content":"Dialogflow sits in the middle between the user and our application, helping us capture conversations from natural language into useful and readable data. \\n\\n**Entities** take care of extracting information and details from what the user says. They are present the moment you create your first intent and start\\ncreating training phrases, Dialogflow will automatically identify and label some words suggesting entities for you to match with an intent.\\n\\nHaving entities set in place will help you train your assistant and make it more efficient for the users. These can be created manually or by a JSON or CSV file.\\n\\nThere are multiple types of entities:\\n\\n- **System entities:**\\n\\nThese are default entities of Dialogflow and they match many types of common words like geographic locations or dates.\\n \\n```\\n@sys.date\\n```\\n\\n- **Custom or developer entities:**\\n\\nThese allow you to define your own words to trigger an intent, you can also provide synonyms. \\n\\nThey come in handy when building your own assistant with specific words you want it to listen to and identify so you can provide \\nan accurate response to your users. \\n\\nJust remember that when providing a custom name, it can start with a letter, number, dash or underscore. \\n\\n```\\n@computer_service\\n```\\n\\n  - **Custom or developer composite entities:**\\n   These are built from multiple custom entities linked to be triggered together. \\n   \\n   ```\\n   @os_computer[@os_device @computer_service]\\n   ```\\n- **Session entities:**\\n\\nThey are generated for a single user-specific session, from one conversation between the agent and the user.\\n\\nThese entities expire automatically after 20 minutes. \\n\\n- **Regexp entities:**\\n\\nThese utilize Regular Expressions to match more specialized entities from the user.\\n\\nIt is important to remember that the order in which you present your regular expressions to the agent matter because the search will stop once a valid match is found.\\n\\n## Entity vs Intent \\n\\n**Entities** will make your development time quicker and, once identified by the agent, provide accurate responses to the interaction at hand. They are the way you have to catch important data from the user. **Intent** helps understand what the user request really means, it usually contains training phrases that help it identify what the end-user expression wants, actions to be performed after an intent is identified, parameters that will form the entity and dictate how data is extracted and responses that will be returned to the end-user.\\n\\n\\n### Join the conversation \\n\\nFonoster is developed in the open. Here are some of the channels you can use to reach us: \\n\\n[Discord](https://discord.gg/4QWgSz4hTC)\\n\\n**GitHub discussions:**\\n- [Q&A](https://github.com/fonoster/fonoster/discussions/categories/q-a) \\n\\n**Twitter:** [@fonoster](https://twitter.com/fonoster)"},{"id":"Differences in types of Conversational Interfaces","metadata":{"permalink":"/blog/Differences in types of Conversational Interfaces","editUrl":"https://github.com/fonoster/website/edit/main/docs/blog/blog/2023-02-28-Differences_in_types_of_conv_interfaces.md","source":"@site/blog/2023-02-28-Differences_in_types_of_conv_interfaces.md","title":"Differences in types of Conversational Interfaces","description":"There are 3 main types of Conversational Interfaces.","date":"2023-02-28T00:00:00.000Z","formattedDate":"February 28, 2023","tags":[{"label":"fonoster","permalink":"/blog/tags/fonoster"},{"label":"voice","permalink":"/blog/tags/voice"},{"label":"OSS","permalink":"/blog/tags/oss"},{"label":"VUI","permalink":"/blog/tags/vui"}],"readingTime":1.335,"hasTruncateMarker":false,"authors":[{"name":"Yuri Santana","title":"Developer Relations Advocate at Fonoster","url":"https://github.com/yuricodes","imageURL":"https://github.com/yuricodes.png","key":"yuricodes"}],"frontMatter":{"slug":"Differences in types of Conversational Interfaces","title":"Differences in types of Conversational Interfaces","authors":["yuricodes"],"tags":["fonoster","voice","OSS","VUI"]},"prevItem":{"title":"Dialogflow entities. Capturing useful data.","permalink":"/blog/Dialogflow entities"},"nextItem":{"title":"The most common user interface design elements","permalink":"/blog/common user interface design elements"}},"content":"There are 3 main types of Conversational Interfaces. \\nDepending on the most appropriate for your users, we can establish some very clear differences and elements in common between them.\\n\\n![Conceptual diagram of speech systems (3)](https://user-images.githubusercontent.com/80093500/221926362-2f81e5d9-ad15-4c61-8b5e-2c2fe9ce5002.png)\\n\\n**Voice applications** \\n\\nThey let you complete your task and control your device with spoken commands. In return you\'ll get audible responses from the application. \\n\\nThese are the elements of a voice-only interface: \\n\\n- Voice commands \\n- Audible response from assistant \\n- Audible list of options \\n- Descriptive options for users\\n- Sometimes a button is present to help start or end conversation \\n\\n**Text applications**\\n\\nAlso known as chat applications, they allow the user to complete their task and interact with the interface by sending and receiving messages.\\n\\nThese are the elements of a text-only interface: \\n\\n- Text Commands\\n- Written response from assistant with sound \\n- Written list of options\\n- Video or Images to help the users make a choice\\n- Button available to make certain selections easier\\n\\n**Multimodal applications**\\n\\nThey allow the user to interact with the interface by combining different features from voice and text, taking advantage of the strengths of each. \\n\\nThese are the elements of a multimodal interface: \\n\\n- Voice or Text Commands\\n- Written or audible response from assistant\\n- Audible or written list of options \\n- Video or Images to help the users make a choice\\n- Button available to make certain selections easier\\n\\n\\n\\n<hr />\\n\\n### Join the conversation \\n\\nFonoster is developed in the open. Here are some of the channels you can use to reach us: \\n\\n[Discord](https://discord.gg/4QWgSz4hTC)\\n\\n**GitHub discussions:**\\n- [Q&A](https://github.com/fonoster/fonoster/discussions/categories/q-a) \\n\\n**Twitter:** [@fonoster](https://twitter.com/fonoster)"},{"id":"common user interface design elements","metadata":{"permalink":"/blog/common user interface design elements","editUrl":"https://github.com/fonoster/website/edit/main/docs/blog/blog/2023-02-23-common_elements_designing_VUI.md","source":"@site/blog/2023-02-23-common_elements_designing_VUI.md","title":"The most common user interface design elements","description":"There are multiple conversation design elements that we keep witnessing pop up in each assistant interaction that are based on conversational interface design principles.","date":"2023-02-23T00:00:00.000Z","formattedDate":"February 23, 2023","tags":[{"label":"fonoster","permalink":"/blog/tags/fonoster"},{"label":"voice","permalink":"/blog/tags/voice"},{"label":"OSS","permalink":"/blog/tags/oss"},{"label":"VUI","permalink":"/blog/tags/vui"}],"readingTime":3.45,"hasTruncateMarker":false,"authors":[{"name":"Yuri Santana","title":"Developer Relations Advocate at Fonoster","url":"https://github.com/yuricodes","imageURL":"https://github.com/yuricodes.png","key":"yuricodes"}],"frontMatter":{"slug":"common user interface design elements","title":"The most common user interface design elements","authors":["yuricodes"],"tags":["fonoster","voice","OSS","VUI"]},"prevItem":{"title":"Differences in types of Conversational Interfaces","permalink":"/blog/Differences in types of Conversational Interfaces"},"nextItem":{"title":"Advantages of Voice User Interface Applications","permalink":"/blog/Advantages of VUI applications"}},"content":"There are multiple conversation design elements that we keep witnessing pop up in each assistant interaction that are based on conversational interface design principles. \\n\\nThese elements are those present in human interactions and help the user in the task they want to fulfill, reducing frustration and increasing user satisfaction levels. Some of the most common ones are: \\n\\n- **Welcome message, greeting and farewell**\\n\\nThe assistant should introduce itself and state its function so the user knows what to expect from the interaction. \\n\\nExample: \\"Hello! I\'m Alex and I can help you set up an appointment.\\"\\n\\nThe farewell message should inform the user of the status of the request and end the interaction.\\n\\nExample: \\"Your appointment has been set for X. Thank you for scheduling. Goodbye.\\"\\n\\n- **Questions and feedback** \\n\\nQuestions redirect the user and help clarify the intent this one has when interacting with our interface. They help us collect useful information and keep the user engaged in the conversation. \\n\\nExample: \\"Would you rather make an appointment for today or tomorrow?\\" \\n\\n- **Feedback and confirmation messages**\\n\\nIt should be a must in every interaction with the assistant. It lets the user know the assistant is working on their request, if it was confused or if it needs clarifying details. More importantly, it lets the user know the assistant understands their intent and they\'re working together to address their request. \\n\\nExample: \\"Okay, I\'ll schedule it for tomorrow morning.\\" \\n\\n- **Informational interactions and suggestions** \\n\\nInformational interactions are those that present information in a way to answer questions. They provide a general overview of options and it\'s often followed by a question prompting the user to pick one of the choices presented in the message. \\n\\nExample: \\"We have the following [list of hours] available for tomorrow. Would you like to know more about the slots?\\" \\n\\nSuggestions help the user pick an option that is understandable by our assistant. It can also guide the user to the best option available providing new information.\\n\\nExample: \\"If you pick the 2pm slot it comes with a 50% discount for future appointments. Would you be interested in that?\\"\\n\\n- **Apology statements and useful commands** \\n\\nIdeally, apology statements won\'t be necessary, but when mistakes happen or the users intent is not clear to the assistant, they should quickly apologize and redirect the user to another option available. \\n\\nExample: \\"Unfortunately, we don\'t have 4pm slots available. Would you like to have a 5pm slot? \\"\\n\\nWhen the issue keeps on happening, the apology statements should include understanding of the users problem, accepting responsability, explaining the issue, solving it and expressing gratitude for the user\'s understanding.  \\n\\nExample: \\"I understand how [customer\u2019s feelings \u2013 i.e frustrating, upsetting] this problem has been for you. I\u2019m sorry that you\u2019ve had to deal with [the issue]. The issue happened because we [what caused the issue]. To prevent it from happening again [what we will do]. \\nThank you for bearing with us through this incident. If there\u2019s anything else I can help you with, please let me know. \\"\\n\\nUseful commands should be available at all stages of the conversation. It directs the users to what the assistant understands and how they can get there. \\n\\nExample: \\"Would you like to continue? Yes - No \\"\\n\\n- **Buttons and interactive elements**\\n\\nButtons are visual elements that help the user to quickly pick between different options presented to them. They can be accompanied by images or extra text to aid the decision making. \\n\\nExample: \\"It has been scheduled. What would you like to do next? \\n- Button 1: Check out directions \\n- Button 2: Check out parking \\"\\n\\nMultiple interactive elements help construct a multi-modal assistant. They utilize audio, emojis, images, videos and more to help the user make a decision and help showcase the assistants\' personality. \\n\\nExample: \\"It has been scheduled [confirmation sound]. What would you like to do next? \\"\\n \\nTo know more about _conversational structure_ check out our [video](https://youtu.be/ChqlotD4aDk) about it on YouTube. \\n \\n <hr />\\n\\n\\n### Join the conversation \\n\\nFonoster is developed in the open. Here are some of the channels you can use to reach us: \\n\\n[Discord](https://discord.gg/4QWgSz4hTC)\\n\\n**GitHub discussions:**\\n- [Q&A](https://github.com/fonoster/fonoster/discussions/categories/q-a) \\n\\n**Twitter:** [@fonoster](https://twitter.com/fonoster)"},{"id":"Advantages of VUI applications","metadata":{"permalink":"/blog/Advantages of VUI applications","editUrl":"https://github.com/fonoster/website/edit/main/docs/blog/blog/2023-02-16-advantages_of_VUI.md","source":"@site/blog/2023-02-16-advantages_of_VUI.md","title":"Advantages of Voice User Interface Applications","description":"VUIs (Voice User Interfaces) is the ability a virtual assistant has to respond to a voice commands utilizing NLU (Natural Language Understanding), NLP (Natural Language Processing) and speech recognition technologies.","date":"2023-02-16T00:00:00.000Z","formattedDate":"February 16, 2023","tags":[{"label":"fonoster","permalink":"/blog/tags/fonoster"},{"label":"voice","permalink":"/blog/tags/voice"},{"label":"OSS","permalink":"/blog/tags/oss"},{"label":"VUI","permalink":"/blog/tags/vui"},{"label":"Dialogflow","permalink":"/blog/tags/dialogflow"}],"readingTime":2.925,"hasTruncateMarker":false,"authors":[{"name":"Yuri Santana","title":"Developer Relations Advocate at Fonoster","url":"https://github.com/yuricodes","imageURL":"https://github.com/yuricodes.png","key":"yuricodes"}],"frontMatter":{"slug":"Advantages of VUI applications","title":"Advantages of Voice User Interface Applications","authors":["yuricodes"],"tags":["fonoster","voice","OSS","VUI","Dialogflow"]},"prevItem":{"title":"The most common user interface design elements","permalink":"/blog/common user interface design elements"},"nextItem":{"title":"The way VUIs are reshaping human-device interactions","permalink":"/blog/The way VUIs are reshaping human-device interactions"}},"content":"VUIs _(Voice User Interfaces)_ is the ability a virtual assistant has to respond to a voice commands utilizing NLU _(Natural Language Understanding)_, NLP _(Natural Language Processing)_ and speech recognition technologies. \\n\\nSpeech is more intuitive and natural for humans to communicate with each other while it also helps us gain important information and context, this is why voice assistants have become more popular in the last year with multiple uses from home, health, entertainment, businesses and many other sectors. \\n\\nVUI technology is becoming more sophisticated and reliable, being fast to adopt and leaving the users with higher satisfaction levels than conventional chat or text assistants. \\n\\nBut **what are the real advantages of Voice and Speech recognition technology?** \\n\\n- **Users don\u2019t need to be trained on how to use the interface** \\n\\nFinding and understanding how to use new features on a system can be difficult, especially for new users. When you have many menus, dropdowns or information to display to the user they can feel overwhelmed and frustrated to not know how to pick what they\u2019re looking for.\\n\\nVoice can help ease the user to reach their goal on your product faster, just by voicing a command to the assistant and finding what they\u2019re looking for immediately, offering more flexibility than a text/visual only interface.\\n\\n- **Makes your product more accessible for the users**\\n\\nAccessibility is essential in this day and age, we have all suffered from a disability whether that is temporary or permanent so making your product accessible is a must. \\n\\nMany groups of individuals rely on voice features to navigate the internet completely and even people who want to limit their keyboard use due to fatigue or cognitive disabilities. \\n\\nIncorporating voice will help include a good section of the population that is often overlooked, placing you and your product in the competitive advantage in front of those with less accessible products for the users. \\n\\n- **Boost productivity levels** \\n\\nVoice can provide support and assistance to customer support or task management, it allows you access to the information you need with just one voice command, taking less time than it would to type out a query on a text or visual only interface. Stanford\u2019s study has stated that speech is three times faster than typing. \\n\\nVoice prevents you from having to use hardware to achieve your goal, for example taking out your phone to get a direction from Google Maps, minimizing the risk of accidents. \\n\\n- **Users will connect with your brand and product** \\n\\nVoice for the users feels more like a human interaction, providing comfort when the VUI actually understands what the user is saying and providing an accurate response to the intent and feeling of the user. \\n\\nVoice provides a personality to your brand, it can be programmed to have humor, to be kind or to be friendly. All of those human traits the VUI learns over time, will make the user feel more connected to the brand.\\n\\n <hr />\\n\\nSpeech has the freedom that it can be applied for any industry, so the benefits are not only for the tech community. Voice can significantly improve the user experience and make the interaction with the product be more efficient. It ultimately, when done correctly, combines the best of the graphical and voice interfaces in benefit for the user reducing time and fatigue. \\n\\n<hr />\\n\\n\\n### Join the conversation \\n\\nFonoster is developed in the open. Here are some of the channels you can use to reach us: \\n\\n[Discord](https://discord.gg/4QWgSz4hTC)\\n\\n**GitHub discussions:**\\n- [Q&A](https://github.com/fonoster/fonoster/discussions/categories/q-a) \\n\\n**Twitter:** [@fonoster](https://twitter.com/fonoster)"},{"id":"The way VUIs are reshaping human-device interactions","metadata":{"permalink":"/blog/The way VUIs are reshaping human-device interactions","editUrl":"https://github.com/fonoster/website/edit/main/docs/blog/blog/2023-01-19_how_VUI_is_changing_user_machine_interaction.md","source":"@site/blog/2023-01-19_how_VUI_is_changing_user_machine_interaction.md","title":"The way VUIs are reshaping human-device interactions","description":"What we\u2019re dealing with is the technology of conversation - Harvey Sacks","date":"2023-01-19T00:00:00.000Z","formattedDate":"January 19, 2023","tags":[{"label":"fonoster","permalink":"/blog/tags/fonoster"},{"label":"voice","permalink":"/blog/tags/voice"},{"label":"OSS","permalink":"/blog/tags/oss"},{"label":"VUI","permalink":"/blog/tags/vui"}],"readingTime":2.255,"hasTruncateMarker":false,"authors":[{"name":"Yuri Santana","title":"Developer Relations Advocate at Fonoster","url":"https://github.com/yuricodes","imageURL":"https://github.com/yuricodes.png","key":"yuricodes"}],"frontMatter":{"slug":"The way VUIs are reshaping human-device interactions","title":"The way VUIs are reshaping human-device interactions","authors":["yuricodes"],"tags":["fonoster","voice","OSS","VUI"]},"prevItem":{"title":"Advantages of Voice User Interface Applications","permalink":"/blog/Advantages of VUI applications"},"nextItem":{"title":"Steps for building conversational interfaces","permalink":"/blog/Steps for building conversational interfaces"}},"content":"> _What we\u2019re dealing with is the technology of conversation_ - Harvey Sacks \\n\\nVoice user interfaces (VUI) are applications where the main form of interaction is speech. \\nThey allow users to interact with software by speaking to them.\\n\\n## VUI benefits \\n\\nThe language the user can utilize is way more natural than typing on chat applications and the conversations are mostly engineered to simulate the way we would interact with another person. \\nWhen done right, they can eliminate the use of keypads, buttons or graphic interfaces and reduce user frustration.\\n\\nVUIs also help make your products more accessible to those faced with the significant barriers that graphic interfaces inevitably impose on those with disabilities, both individual and situational. \\nInteracting with software using voice is a way of making sure your product is accessible to those in situations where hands and eyes might be preoccupied.  \\n\\n## VUI popularity \\n\\nThe use of speech is then the best solution for what Dario D. Salvucci calls _secondary-task interfaces_ in his paper on _Predicting the effects of in-car interface use on driver performance: an integrated model approach_, those that are for support on a _primary more critical task_ like driving, where the safety can be compromised when the other senses are involved if you\u2019re checking your phone for example to get the weather.\\n \\nIn the past year, 2022, we have seen that [71%](https://www.oberlo.com/blog/voice-search-statistics%23:~:text=Voice%2520Search%2520Popularity%2520in%2520The%2520United%2520States,-An%2520increasing%2520number&text=And%2520all%2520signs%2520point%2520to,devices%2520among%2520voice%2520search%2520users) of users prefer using voice for search queries instead of graphic interfaces, nearly 1 out of 3 US consumers own at least one smart device and more than half of all owners use their device on a daily basis. \\nThe most well known VUIs include Google Assistant, Amazon\u2019s Alexa and Apple\u2019s Siri. For smart devices, we have Amazon Echo, a newly released Apple HomePod and Google Home.\\n\\n## The future for VUIs\\n\\nThis overwhelming popularity of voice interfaces makes us evaluate the impact of assistants on human - machine interactions. When users are faced with the option of a chat or voice assistant to get support, more than half choose the latter. \\nThis is because of natural language understanding (NLU), and natural language processing (NLP) the user can communicate their frustration or doubts effectively using their voice rather than pre-conceived options on a screen. \\n\\nUsers are now actively choosing to speak with the machine, and with the increase of AI assistants and VUI devices, we\u2019ll soon discover even more usages and ways to apply Voice Interfaces to our applications and web pages and the undeniable effects these interactions will have on business-customer machine-user relationships. \\n\\n### Connect with us \\n\\nFonoster is developed in the open. Here are some of the channels you can use to reach us: \\n\\n[Discord](https://discord.gg/4QWgSz4hTC)\\n\\n**GitHub discussions:**\\n- [Q&A](https://github.com/fonoster/fonoster/discussions/categories/q-a) \\n\\n**Twitter:** [@fonoster](https://twitter.com/fonoster)"},{"id":"Steps for building conversational interfaces","metadata":{"permalink":"/blog/Steps for building conversational interfaces","editUrl":"https://github.com/fonoster/website/edit/main/docs/blog/blog/2023-01-12-steps_for_creating_conversational_interfaces.md","source":"@site/blog/2023-01-12-steps_for_creating_conversational_interfaces.md","title":"Steps for building conversational interfaces","description":"A conversational user interface (CUI) is the way users interact with software through language-understanding interfaces, whether that\u2019s text or voice.","date":"2023-01-12T00:00:00.000Z","formattedDate":"January 12, 2023","tags":[{"label":"fonoster","permalink":"/blog/tags/fonoster"},{"label":"voice","permalink":"/blog/tags/voice"},{"label":"OSS","permalink":"/blog/tags/oss"}],"readingTime":4.47,"hasTruncateMarker":false,"authors":[{"name":"Yuri Santana","title":"Developer Relations Advocate at Fonoster","url":"https://github.com/yuricodes","imageURL":"https://github.com/yuricodes.png","key":"yuricodes"}],"frontMatter":{"slug":"Steps for building conversational interfaces","title":"Steps for building conversational interfaces","authors":["yuricodes"],"tags":["fonoster","voice","OSS"]},"prevItem":{"title":"The way VUIs are reshaping human-device interactions","permalink":"/blog/The way VUIs are reshaping human-device interactions"},"nextItem":{"title":"Connect Fonoster to Dialogflow","permalink":"/blog/Connect Fonoster to Dialogflow"}},"content":"A conversational user interface (CUI) is the way users interact with software through language-understanding interfaces, whether that\u2019s text or voice. \\n\\nIt is formulated to emulate human interaction and that is reflected every step of the way. \\n\\nPrior to starting building your conversational interface, it\u2019s important to have several aspects pre-defined to make the development and design process more clear and direct. \\n\\n# Before building a conversational interface \\n\\nYou will need to have a clear vision on the following aspects: \\n\\n<ul>\\n  <li> <strong> Type of interaction </strong> </li>\\n  \\n  Is the user going to interact with the app using text? Using voice? or a mix of both?\\n  This will depend entirely on the needs your company has and the type of interaction your users need. \\n\\n  <li> <strong> Goal of interaction </strong> </li>\\n  \\n  Is it transactional or relational? Do you want your users to buy something? \\n  This will completely shape the word and interaction design to fit the needs as appropriate. \\n  \\n  <li> <strong> Domain of knowledge </strong> </li>\\n  \\n  Is your app going to be  generalist? Would you be able to talk with it about anything or is it going to be a specialist? Focused on your product and specific topics surrounding it? \\n  This will not only limit and craft the development process but also help with the conversation design.\\n  \\n  <li> <strong> Who takes the initiative </strong> </li>\\n  \\n  Is it going to be proactive and lead the conversation or reactive and respond only when prompted by the user? \\n  \\n  <li><strong> Depth of conversation</strong> </li>\\n  \\n   Is it a single shift or a multi-turn conversation with the user?\\n</ul>\\n\\n\\n# Steps for creating conversational interfaces \\n\\n## Product design\\n\\nIt should involve the tech side, business knowledge and what your users need. \\n\\nCreate a list of possible functionalities and eliminate, according to your already established goal of interaction, domain of knowledge and depth of conversation. Define those that will end as part of the minimum viable product (MVP).\\n\\n## Conversation structure \\n\\nThis is the point where your team needs to start crafting the happy path your application will follow. \\nYou will also need to define the order the information will be presented to the user after a keyword is identified from their input to trigger a search query into your database. \\n\\nTo know more about conversation structure, check out Fonoster\u2019s video on [Conversational Interface Design](https://youtu.be/ChqlotD4aDk)\\n\\n## Interaction design\\n\\nMuch like conversation structure, your team will need to design how to solve each of the presented interactions on the Happy Path, presenting the user with several options or \u2018paths\u2019 they can trigger on the application that will take them to their desired outcome with no friction. \\n\\nFor your application to learn, conversational patterns must be used to craft it based on the ideal interaction between the app and the user.\\n\\n## Word design\\n\\nPicking the exact words to provoke actions in your users is a science by itself. That\u2019s why it\u2019s important to choose specific words and sounds that will make the user reach the goal we want.  \\n\\nWe can aid ourselves by asking open, closed or yes or no questions. Users have a better time responding to \u2018which country would you like to visit?\u2019 than to \u2018where do you want to go\u2019.  \\n\\n## Personality design \\n\\nThis is where your team designs the aspects that define your assistant. Your team should be able to identify how the assistant will respond to specific circumstances and how it\u2019s never going to respond. \\n\\nThis is usually where an avatar is created with the demographic characteristics of the assistant and the behavior is defined extensively. \\n\\n## Sound design \\n\\nIt is now time to define the sound of your assistant. Is it going to be an automated voice or a voice actor? \\n\\nThis also includes setting up the sound effects that will be played when opening or closing the assistant. \\n\\n#  After building \\n\\n## Prototype and testing \\n\\nNow that our conversational interface prototype is ready to be released to our users, it\u2019s important to keep on listening to feedback to see which features are working and which ones need to be polished or deleted. \\n\\nYou can begin testing within your own team or community by reading the conversation structure out loud and noticing how they respond to certain choices or paths presented. Remember the goal is to simulate human to human interaction. This is called <strong> analog testing </strong>.\\n\\nYou can also submit your conversation structure to a platform that will act as a user, allowing you to identify issues and corner cases. This is called <strong> automated testing. </strong>\\n\\nLastly, we have <strong> beta testing.</strong> It is done by taking a selected group of users and, making the application available for them to get feedback from  your own community before releasing it to a bigger audience. \\n\\n ## Metrics \\n\\nAfter you have made your application available to your users, one quick way to identify if it\u2019s working or which features are the ones they prefer is by analyzing metrics. \\n\\nThis will allow you to know if the objective the user has set has been met by the application, help you correct interactions and questions and which utterances you should train your interface on. \\n\\nThere are many software applications to know the metrics of both text and voice interfaces, they should give you a clear view of the users, recurrency, functionalities and where your users are abandoning your assistant."},{"id":"Connect Fonoster to Dialogflow","metadata":{"permalink":"/blog/Connect Fonoster to Dialogflow","editUrl":"https://github.com/fonoster/website/edit/main/docs/blog/blog/2022-11-15-connect_fonoster_to_dialogflow.md","source":"@site/blog/2022-11-15-connect_fonoster_to_dialogflow.md","title":"Connect Fonoster to Dialogflow","description":"Connecting Fonoster to Dialogflow is just a few clicks away using the Fonoster Dashboard.","date":"2022-11-15T00:00:00.000Z","formattedDate":"November 15, 2022","tags":[{"label":"fonoster","permalink":"/blog/tags/fonoster"},{"label":"voice","permalink":"/blog/tags/voice"},{"label":"dialogflow","permalink":"/blog/tags/dialogflow"},{"label":"OSS","permalink":"/blog/tags/oss"}],"readingTime":1.39,"hasTruncateMarker":false,"authors":[{"name":"Yuri Santana","title":"Developer Relations Advocate at Fonoster","url":"https://github.com/yuricodes","imageURL":"https://github.com/yuricodes.png","key":"yuricodes"}],"frontMatter":{"slug":"Connect Fonoster to Dialogflow","title":"Connect Fonoster to Dialogflow","authors":["yuricodes"],"tags":["fonoster","voice","dialogflow","OSS"]},"prevItem":{"title":"Steps for building conversational interfaces","permalink":"/blog/Steps for building conversational interfaces"},"nextItem":{"title":"Accessibility in Open Source","permalink":"/blog/Accessibility in Open Source"}},"content":"Connecting Fonoster to Dialogflow is just a few clicks away using the Fonoster Dashboard. \\n\\n**Trunking information you\'ll need:**\\n- VoIP provider\\n- Number\\n- Username\\n- Password\\n- Host\\n\\n## Set up your provider\'s information\\nSign in to Fonoster and go to the Fonoster Project Dashboard, next select SIP Network tab and create a new Trunk.\\n\\nHere you\'ll need to provide this information from your provider\'s account:\\n- Your provider\'s name\\n- Your username \\n- Your secret / password\\n- Providers Hostname or IPv4\\n\\n### Google Service Account key\\nNext step, you\'ll need to create a new Secret on the Secrets tab and set it to be the Google Service Account json key.\\n\\n#### Create a new Fonoster Application \\n\\nNow we are ready to create a new Application, go to the Applications tab and create a new one. \\n- Pick a name\\n- Select the secret you previously added from the previous step\\n- Pick a voice\\n- Type the intent ID from your Dialogflow Agent\\n- Type the project ID from your Dialogflow project\\n- Hit save\\n\\n##### Add a new number to call \\n\\nLastly, we need to add a new number we can call and trigger Dialogflow.\\n\\nCreate a new number from the SIP Network tab\\n- Add your number from the provider\\n- Add the weebhook URL ```http://voice.fonoster:3000```\\n- Click save\\n\\nAnd there you have it. You\'re ready to call that number and be able to interact with the AI. \\n\\n###### Need help?\\n\\nFonoster is developed in the open. Here are some of the channels you can use to reach us: \\n\\n[Discord](https://discord.gg/4QWgSz4hTC)\\n\\n**GitHub discussions:**\\n- [Q&A](https://github.com/fonoster/fonoster/discussions/categories/q-a) \\n\\n**Twitter:** [@fonoster](https://twitter.com/fonoster)\\n\\nWe look forward to hearing from you."},{"id":"Accessibility in Open Source","metadata":{"permalink":"/blog/Accessibility in Open Source","editUrl":"https://github.com/fonoster/website/edit/main/docs/blog/blog/2022-10-19-Accessibility_in_Open_Source.md","source":"@site/blog/2022-10-19-Accessibility_in_Open_Source.md","title":"Accessibility in Open Source","description":"Hear the full conversation","date":"2022-10-19T00:00:00.000Z","formattedDate":"October 19, 2022","tags":[{"label":"fonoster","permalink":"/blog/tags/fonoster"},{"label":"voice","permalink":"/blog/tags/voice"},{"label":"twitter","permalink":"/blog/tags/twitter"},{"label":"OSS","permalink":"/blog/tags/oss"}],"readingTime":2.87,"hasTruncateMarker":false,"authors":[{"name":"Yuri Santana","title":"Developer Relations Advocate at Fonoster","url":"https://github.com/yuricodes","imageURL":"https://github.com/yuricodes.png","key":"yuricodes"}],"frontMatter":{"slug":"Accessibility in Open Source","title":"Accessibility in Open Source","authors":["yuricodes"],"tags":["fonoster","voice","twitter","OSS"]},"prevItem":{"title":"Connect Fonoster to Dialogflow","permalink":"/blog/Connect Fonoster to Dialogflow"},"nextItem":{"title":"How we created an open-source alternative to Twilio and why it matters","permalink":"/blog/How we created an open-source alternative to Twilio and why it matters"}},"content":"## Hear the full conversation\\n- <a href=\\"https://twitter.com/yuricodesbot/status/1582355852895612929?s=20&t=1MUUhhOnp5OCNBXG71EO2w\\" target=\\"_blank\\"> Pt.1 </a>\\n- <a href=\\"https://twitter.com/yuricodesbot/status/1582366732819177472?s=20&t=1MUUhhOnp5OCNBXG71EO2w\\" target=\\"_blank\\"> Pt.2 </a>\\n\\nWe had a lovely conversation with  <a href=\\"https://twitter.com/GrahamTheDev\\" target=\\"_blank\\"> Graham </a> an accessibility expert who gave us some wonderful insights on how to test our contrast levels, why accessibility matters and how to fix common mistakes. Let\'s see some of the main points covered in the conversation. \\n\\n> Accessibility is not only important for people with disabilities, we all see and experience the benefits.\\n\\nThere\u2019s this enormous field of software development that people do not know much about. That is accessibility. \\n\\n## How can we make low-code non-code contributions more accessible?\\n\\nFrom an accessibility point, structure your headings correctly, they shouldn\u2019t be nested on each other. There should always be one Heading 1 per page. Do not use them because they\u2019re pretty, use them for their intended purpose. This is important for people using screen readers. \\n\\nUse labels on forms. Do not replace them with placeholders. This is an issue for people in general. For example, someone anxious might fill out the form but wants to double check the form and starts questioning which field is which, so they can only delete the information and see the placeholder text and see if they filled it out right. This is pretty inconvenient.\\n\\nThe second point is alt text on images. Try describing the picture as if you were talking to someone on the phone. And last thing, if there are pictures of code snippets you should fix that and turn it into actual code snippets, for both accessibility and speed for people to copy your code. Ex.\\n\\n```none\\nSome code you can copy\\n``` \\n### Why is accessibility important?\\n\\n- Accessibility not only improves your code or life, but improves other people\u2019s as well. \\n- 97.4% of websites overall have accessibility errors bad enough to stop someone with a disability from using that website.\\n- 1 in 10 people have a disability and 1 in every 10 people have a disability that affects how they interact with web pages.\\n\\nBut we can approach this from two angles. **How does this affect me as a developer?**\\n\\nWell, it makes you use best practices, makes you use semantic HTML, it will save you time, ex: with the button tag. And makes your code easier to read and understand for future checks and reviews. \\n\\nThe other perspective is the business one. There\u2019s a billion people in the world who care about accessibility because they have family or they themselves are disabled, so when you cater to those audiences, you can outperform your competition and have a bigger market. \\n\\nAnother reason why you should care is that the things you do for those with disabilities can help those without disabilities.\\n\\n#### Tips to make your projects more accessible\\n\\nYou need to know how to identify problems. There are tools that help with this issue, like [Accessibility Insights](https://accessibilityinsights.io/). It\u2019ll pick up color contrast issues, if you used the wrong HTML element, the focus order on the page, among some other useful features. \\n\\nRead about accessibility, learn about semantic HTML and best practices. Consume content that can help you improve the structure of your code and make sure to run it through accessibility checkers or make sure to apply [Accessibility Guidelines](wuhecag.com) specifications.  \\n\\n### Other resources:\\n\\n- [Semantic HTML](https://yuricodesbot.hashnode.dev/use-this-instead-of-divs)\\n- [The Internet is not for everyone](https://yuricodesbot.hashnode.dev/the-case-for-web-accessibility)\\n- [Color contrast analyzer for Windows](https://www.tpgi.com/color-contrast-checker/)\\n- [Accessibility Guidelines](wuhecag.com)"},{"id":"How we created an open-source alternative to Twilio and why it matters","metadata":{"permalink":"/blog/How we created an open-source alternative to Twilio and why it matters","editUrl":"https://github.com/fonoster/website/edit/main/docs/blog/blog/2022-10-05-How_we_created_an_open_source_alternative_to_Twilio_and_why.md","source":"@site/blog/2022-10-05-How_we_created_an_open_source_alternative_to_Twilio_and_why.md","title":"How we created an open-source alternative to Twilio and why it matters","description":"Last year, when I started assembling Team Fonoster, I published a post on Reddit that sparked a great conversation and placed Fonoster on Github\'s trending list even though we didn\'t have much to show.","date":"2022-10-05T00:00:00.000Z","formattedDate":"October 5, 2022","tags":[{"label":"fonoster","permalink":"/blog/tags/fonoster"},{"label":"voice","permalink":"/blog/tags/voice"},{"label":"javascript","permalink":"/blog/tags/javascript"}],"readingTime":3.945,"hasTruncateMarker":false,"authors":[{"name":"Pedro Sanders","title":"CTO at Fonoster","url":"https://github.com/psanders","imageURL":"https://github.com/psanders.png","key":"psanders"}],"frontMatter":{"slug":"How we created an open-source alternative to Twilio and why it matters","title":"How we created an open-source alternative to Twilio and why it matters","authors":["psanders"],"tags":["fonoster","voice","javascript","voice"]},"prevItem":{"title":"Accessibility in Open Source","permalink":"/blog/Accessibility in Open Source"},"nextItem":{"title":"Deploying Fonoster with Cloud-Init","permalink":"/blog/Deploying Fonoster with Cloud-Init"}},"content":"Last year, when I started assembling Team Fonoster, I published a [post](https://www.reddit.com/r/Entrepreneur/comments/j96avf/an_opensource_alternative_to_twilio/) on Reddit that sparked a great conversation and placed Fonoster on Github\'s trending list even though we didn\'t have much to show.\\n\\nAs a result, I had the opportunity to interview dozens of CTOs from companies worldwide and speak with several investors who were interested in the idea of an open-source stack of Programmable Telecommunications.\\n\\nIn the interviews, I found we need an innovative approach to a cloud-based stack for Programmable Telecommunications.\\n\\n## Why we needed CPaaS in the first place?\\n\\nBuilding an application that takes advantage of the existing Telecom network has always been a difficult task compared with, for example, building a web-based application.\\n\\nThis is difficult because it involves a particular set of skills that is challenging to find and can get really costly.\\n\\nLet\'s face it, no one wants to read through dozens of RFCs to program a phone call.\\n\\nSo, when the API era arrived along with UCaaS and CPaaS providers, it was a no-brainer to use one of those providers to deploy a solution within weeks instead of spending months only to get a simple use-case.\\n\\n## So what\'s wrong with traditional CPaaS?\\nThere is nothing wrong with traditional CPaaS. In fact, in most cases, using a CPaaS is a great option to deploy a Telecommunications solution.\\n\\nHowever, even though the concept of using a CPaaS to go to market quickly is fantastic, it comes at a high price for some use-cases. After all, if something goes wrong, you will have no other option but to migrate to another CPaaS or build your own solution and start again on square zero.\\n\\nSome companies complain about the high prices for using a CPaaS. A startup CTO once told me, \u201cIt almost feels that we are paying for a lot of features we don\'t need.\u201d This is because, with a traditional CPaaS, you start on a pay-as-you-go model, but costs can quickly get out of control.\\n\\nOther companies find themselves limited by their providers\' features because with traditional CPaaS you have no option but to use what they have available. There is no chance for customization. And even though that\'s not a problem for most companies, it is a deal-breaker for technology companies.\\n\\nThen you have use-cases, especially in the healthcare industry, that can\'t benefit from using a traditional CPaaS due to privacy concerns and local regulations.\\n\\nIn which of those categories does your company fall?\\n\\n## How can we make this better?\\nThe primary innovation of Fonoster lies in researching and developing the means for creating a highly portable, cloud-based Programmable Telecommunications stack.\\n\\nThis Programmable Telecommunications stack will allow businesses to call an API to dial, answer a call, establish a video session, send SMS, etc. There won\'t be any concern about what servers and networks are doing with that information in the background.\\n\\nOur overall approach to building Fonoster is to use existing open-source solutions that are best in their class when possible and build our own when necessary. We then integrate this individual open-source software into a cohesive set of APIs that resembles a traditional CPaaS.\\n\\nFor example, to start a simple Voice Application one could write a Javascript code like the one below:\\n```none\\nconst { VoiceServer } = require(\\"@fonoster/voice\\");\\n\\nconst serverConfig = {\\n  pathToFiles: `${process.cwd()}/sounds`,\\n};\\n\\nnew VoiceServer(serverConfig).listen(\\n  async (req, res) => {\\n    console.log(req);\\n    await res.answer();\\n    await res.play(`sound:${req.selfEndpoint}/sounds/hello-world.sln16`);\\n    await res.hangup();\\n  }\\n);\\n```\\n\\nOr to make a call to the telephone network, you could use the SDK and write a simple script like this:\\n```none\\nconst Fonoster = require(\\"@fonoster/sdk\\");\\nconst callManager = new Fonoster.CallManager();\\n\\ncallManager.call({\\n from: \\"9842753574\\",\\n to: \\"17853178070\\",\\n webhook: \\"https://5a2d2ea5d84d.ngrok.io\\"\\n})\\n.then(console.log)\\n.catch(console.error);\\n```\\n\\nWant to create a reminders application? No problem, in few easy steps, you can create and deploy a Cloud Function that will run based on a given Cron schedule.\\n\\nFirst, initialize your Cloud Function with:\\n```none\\nfonoster funcs:init\\n```\\n\\nThen, edit the handler with the following code:\\n```none\\nconst Fonoster = require(\\"@fonoster/sdk\\");\\nconst callManager = new Fonoster.CallManager();\\n\\n// \ud83d\ude80 Let\'s get started\\n// Use fonoster funcs:deploy to send to the cloud functions\\nmodule.exports = async(request, response) => {\\n  await callManager.call({\\n    from: \\"9842753589\\",\\n    to: \\"17853178070\\",\\n    webhook: \\"https://5a2d2ea5d84d.ngrok.io\\"\\n  })\\n  return response.succeed(\\"OK\\");\\n};\\n```\\n\\nFinally, deploy to the Cloud Functions subsystem with a Cron string.\\n```none\\nfonoster funcs:deploy --schedule \\"*/5 * * * *\\"\\n```\\n\\nYou get the idea.\\n\\n> The Cloud Functions capability if offered by the integration with OpenFaaS (by Alex Ellis)\\n\\n### What\'s next?\\nBe sure to check [The essentials of building Voice Applications with Fonoster](https://learn.fonoster.dev/blog/The%20essentials%20of%20building%20Voice%20Applications%20with%20Fonoster) to overview the Programmable Voice features available on Project Fonoster. \\n\\nStar the project on Github and contact us via:\\n\\n- Twitter: [@fonoster](https://twitter.com/fonoster)\\n- Email: fonosterteam@fonoster.com\\n- [Discord](https://discord.com/invite/mpWSRUhG7e)"},{"id":"Deploying Fonoster with Cloud-Init","metadata":{"permalink":"/blog/Deploying Fonoster with Cloud-Init","editUrl":"https://github.com/fonoster/website/edit/main/docs/blog/blog/2022-10-04-Deploying_Fonoster_With_Cloud_init.md","source":"@site/blog/2022-10-04-Deploying_Fonoster_With_Cloud_init.md","title":"Deploying Fonoster with Cloud-Init","description":"At Fonoster Inc, we want to help companies and individuals that wish to adopt Fonoster as their Programmable Telecommunications solution. To help archive this goal, our team uses Cloud-Init for cloud instance initialization.","date":"2022-10-04T00:00:00.000Z","formattedDate":"October 4, 2022","tags":[{"label":"fonoster","permalink":"/blog/tags/fonoster"},{"label":"voice","permalink":"/blog/tags/voice"},{"label":"javascript","permalink":"/blog/tags/javascript"}],"readingTime":2.13,"hasTruncateMarker":false,"authors":[{"name":"Pedro Sanders","title":"CTO at Fonoster","url":"https://github.com/psanders","imageURL":"https://github.com/psanders.png","key":"psanders"}],"frontMatter":{"slug":"Deploying Fonoster with Cloud-Init","title":"Deploying Fonoster with Cloud-Init","authors":["psanders"],"tags":["fonoster","voice","javascript","voice"]},"prevItem":{"title":"How we created an open-source alternative to Twilio and why it matters","permalink":"/blog/How we created an open-source alternative to Twilio and why it matters"},"nextItem":{"title":"The essentials of building Voice Applications with Fonoster","permalink":"/blog/The essentials of building Voice Applications with Fonoster"}},"content":"At [Fonoster Inc](https://fonoster.com/), we want to help companies and individuals that wish to adopt Fonoster as their Programmable Telecommunications solution. To help archive this goal, our team uses Cloud-Init for cloud instance initialization.\\n\\nYou can deploy Fonoster to all major public cloud providers, private cloud infrastructure, and bare-metal installations with Cloud-Init.\\n\\nIn this tutorial, we will also use Multipass.\\n\\nMultipass is a Canonical project that offers a lightweight VM manager for Linux, Windows, and macOS. With Multipass, you can deploy Fonoster on Ubuntu in a local environment in a single command. This deployment method is by far the fastest way to get started with Fonoster.\\n\\n## Requirements\\nBefore you start this tutorial, you will need the following:\\n\\n- [Multipass](https://multipass.run/)\\n- NodeJS 14+ (Use nvm if possible)\\n- Fonoster command-line tool (install with `npm install -g @fonoster/ctl`)\\n\\n## Deploying to Multipass\\n> This method will not automatically enable TLS for you\\n\\nDeploy Fonoster to Multipass with the following steps. First, download the [cloud-config.txt](https://raw.githubusercontent.com/fonoster/fonoster/main/operator/cloud-config.txt) file into a local directory with:\\n```none\\ncurl https://raw.githubusercontent.com/fonoster/fonoster/main/operator/cloud-config.txt -o cloud-config.txt\\n```\\n\\nSince we are running locally, we have to modify the `cloud-config` to discover the private ipv4 instead of the public ipv4.\\n\\nFirst, update `cloud-config` with:\\n\\n```none\\nsed -i.bak -e \\"s#publicv4#privatev4#g\\" \\"cloud-config.txt\\"\\n```\\n\\nThen, from the same directory, fire up Multipass.\\n\\n```none\\nmultipass launch --name fonoster --disk 8G --cpus 2 --mem 4G --cloud-init cloud-config.txt\\n```\\n\\nYou might see a `timed out waiting for initialization to complete`, especially in a slow Internet connection. Don\'t worry. The process will continue in the background.\\n\\nYou can access your VM and continue following the installation process with:\\n\\n```none\\nmultipass shell fonoster\\ntail -f /var/log/cloud-init-output.log\\n```\\nOnce you see \\"Cloud init is done!\\" the process is complete. If everything goes well, you will be able to log in to your Fonoster deployment. To authenticate for the first time to your deployment, first get your admin credentials with:\\n```none\\ncat /opt/fonoster/config/admin_credentials\\n```\\nYour output will look like the one below.\\n```none\\n{\\n   \\"accessKeyId\\": \\"admin\\",\\n   \\"accessKeySecret\\": \\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\\"\\n}\\n```\\nNext, from the host machine, obtain your VM\'s IP with:\\n```none\\nmultipass info fonoster\\n```\\n\\nLook for the entry starting with IPv4.\\n```none\\nName:           fonoster\\nState:          Running\\nIPv4:           192.168.64.39\\n                172.17.0.1\\n                172.24.0.1\\n...\\n```\\n\\nWith the `accessKeyId`, `accessKeySecret`, and your VM\'s IP address, you can now login using the command-line tool or access your server with the SDK.\\n\\n### What\'s next?\\n\\nFor more deployment options, be sure to check the [operator\'s section of Fonoster\'s documentation](https://github.com/fonoster/fonoster/blob/main/docs/operator/deploy-your-server.md). \\n\\nStar the project on [Github](https://github.com/fonoster) and contact us via:\\n\\n- Twitter: [@fonoster](https://twitter.com/intent/follow?screen_name=fonoster)\\n- Email: fonosterteam@fonoster.com\\n- [Discord](https://discord.gg/4QWgSz4hTC)"},{"id":"The essentials of building Voice Applications with Fonoster","metadata":{"permalink":"/blog/The essentials of building Voice Applications with Fonoster","editUrl":"https://github.com/fonoster/website/edit/main/docs/blog/blog/2022-10-03-voice_app_create.md","source":"@site/blog/2022-10-03-voice_app_create.md","title":"The essentials of building Voice Applications with Fonoster","description":"The purpose of this tutorial is to show the basics of Fonoster. Here you will find how to create a Voice Application, add a Number, and then use that Number to originate a call. Please follow the guide in sequence, as each step builds on the last one.","date":"2022-10-03T00:00:00.000Z","formattedDate":"October 3, 2022","tags":[{"label":"fonoster","permalink":"/blog/tags/fonoster"},{"label":"voice","permalink":"/blog/tags/voice"}],"readingTime":6.39,"hasTruncateMarker":false,"authors":[{"name":"Pedro Sanders","title":"CTO at Fonoster","url":"https://github.com/psanders","imageURL":"https://github.com/psanders.png","key":"psanders"}],"frontMatter":{"slug":"The essentials of building Voice Applications with Fonoster","title":"The essentials of building Voice Applications with Fonoster","authors":["psanders"],"tags":["fonoster","voice"]},"prevItem":{"title":"Deploying Fonoster with Cloud-Init","permalink":"/blog/Deploying Fonoster with Cloud-Init"},"nextItem":{"title":"Welcome","permalink":"/blog/welcome"}},"content":"The purpose of this tutorial is to show the basics of Fonoster. Here you will find how to create a Voice Application, add a Number, and then use that Number to originate a call. Please follow the guide in sequence, as each step builds on the last one.\\n\\n# Requirements  \\n\\nBefore you start this guide, you will need the following:\\n\\n- A set of credentials from [here](https://form.typeform.com/to/sDv75mFr) \ud83d\udc48\\n- An account for access to a SIP Service Provider (For US and Canada, we recommend [voip.ms](https://voip.ms/residential))\\n- NodeJS 14+ (Use nvm if possible)\\n- Fonoster command-line tool install with `npm install -g @fonoster/ctl`\\n- Ngrok `install with npm install -g ngrok`\\n\\nYou can login to the server with:\\n\\n```none\\nfonoster auth:login\\n```\\n\\nAnd your output will be similar to:\\n\\n```none\\nAccess your Fonoster infrastructure\\nPress ^C at any time to quit.\\n? api endpoint api.fonoster.io\\n? access key id psanders\\n? access key token *************************...\\n? ready? Yes\\nAccessing endpoint api.fonoster.io... Done\\n```\\n\\nThen, set the default Project: \\n\\n```none\\n# Get the PROJECT_ID of the project using the \'projects:list\' command \\nfonoster projects:use ${PROJECT_ID}\\n```\\n\\n# Creating a basic Voice Application \\n\\nA Voice Application is a server that takes control of the flow of a call. \\n\\nA Voice Application can use any combination of the following verbs:\\n\\n- `Answer` - Accepts the call\\n- `Hangup` - Closes the call\\n- `Play` - It takes an URL or file and streams the sound back to the calling part\\n- `Say` - It takes a text, synthesizes the text into audio, and streams the result\\n- `Gather` - It waits for DTMF events and returns back the result\\n- `SGather` - It listen for a stream DTMF events and returns back the result\\n- `Record` - It records the voice of the calling party and saves the audio on the Storage sub-system\\n- `Mute` - It tells the channel to stop sending media, thus effectively muting the channel\\n- `Unmute` - It tells the channel to allow media flow\\n\\nTo create a Voice Application perform the following steps.\\n\\nFirst, clone the NodeJS example template as follows:\\n\\n```none\\ngit clone https://github.com/fonoster/nodejs-voiceapp\\n```\\nNext, install the dependencies:\\n\\n```none\\ncd nodejs-voiceapp\\nnpm install\\n```\\nFinally, launch the Voice Application with:\\n```none\\nnpm start\\n```\\n\\nYour output will look like this:\\n```none\\ninfo: initializing voice server\\ninfo: starting voice server on @ 0.0.0.0, port=3000\\n```\\n> Your app will live at `http://127.0.0.1:3000.` Be sure to leave the server up!\\n\\n## Using Ngrok to publish your Voice Application \\n\\nNow that we have our Voice Application up and running, we need to make it available on the Internet\u2014\u2014the fastest way to enable public access by using Ngrok. \\n\\nFor example, with ngrok, you can publish a web server with a single command.\\n\\nOn a new console, run Ngrok with the following command:\\n```none\\nngrok http 3000\\n```\\n\\nThe output will look like this:\\n\\n![ngrok_output](https://user-images.githubusercontent.com/80093500/193677206-08190c5d-b1b1-4358-bd32-4b7d62dd99ef.png)\\n\\nLeave this service running, and save the Forwarding URL for use in the next step.\\n\\n## Building a SIP Network \\nA SIP Network has all the building blocks needed to establish communication between two SIP endpoints (i.e., softphone, webphone, cellphone, the PSTN, etc.) We want to configure a Number and route the calls to our Voice Application on this guide.\\n\\nLet\'s start by creating a SIP Service Provider.\\n\\n## Adding a SIP Service Provider\\nA SIP Service Provider is an organization that will terminate your calls to the phone network (or PSTN). \\n\\nYou will need the `username`, `password`, and `host` you obtained from your SIP Service Provider for this section.\\n\\nCreate a new provider with:\\n```none\\nfonoster providers:create\\n```\\n\\nThe output will look similar to this:\\n```none\\nThis utility will help you create a new Provider\\nPress ^C at any time to quit.\\n? friendly name VOIPMS\\n? username 215706\\n? secret [hidden]\\n? host newyork1.voip.ms\\n? transport tcp\\n? expire 300\\n? ready? Yes\\nCreating provider YourServiceProvider... Done\\n```\\n\\n## Adding a SIP Number\\nA Number, often referred to as DID/DOD, is a number managed by your SIP Service provider.\\n\\n> If your Provider doesn\'t accept E164, you can append the `--ignore-e164-validation`\\n```none\\nfonoster numbers:create --ignore-e164-validation\\n```\\n\\nHere is an example of the output:\\n```none\\nThis utility will help you create a new Number\\nPress ^C at any time to quit.\\n? number in E.164 format (e.g. +16471234567) 9842753574    \\n? service provider VOIPMS\\n? aor link (leave empty)\\n? webhook https://5a2d2ea5d84d.ngrok.io # Replace with the value you obtained from Ngrok\\n? ready? Yes\\nCreating number +17853178071... KyjgGEkasj\\n```\\n\\n>  Be sure to replace the information with what was given to you by your Provider.\\n\\n## Creating a SIP Domain\\n\\nA SIP Domain is a space within the SIP Network where SIP entities live (usually SIP Agents). To create a SIP Domain, you can use the command-line tool or the SDK.\\n\\nIn this step, you need to select the Number you just created as your `Egreess Number`. Also, make sure to use an \\"unclaimed\\" `uri` or you will receive this error: \\"\u203a Error: This Domain already exists.\\"\\n\\nCreate a new Domain with:\\n```none\\nfonoster domains:create\\n```\\n\\nYour output will look similar to this:\\n```none\\nThis utility will help you create a new Domain\\nPress ^C at any time to quit.\\n? friendly name Acme Corp\\n? domain uri (e.g acme.com) sip.acme.com\\n? egress number none\\n? egress rule .*\\n? ready? Yes\\nCreating domain Acme Corp... Jny9B_qaIh\\n```\\n> In the demo server, you don\'t need to own the Domain. Any available URI is fair game!\\n\\n## Using the API to make a call\\n\\nTo make a call, you need install the SDK.\\n\\nInstall the SDK, from within the `voiceapp`, with:\\n```none\\nnpm install --save @fonoster/sdk \\n```\\n\\nNext, create the script `call.js` with the following code:\\n```none\\n// This will load the SDK and reuse your Fonoster credentials\\nconst Fonoster = require(\\"@fonoster/sdk\\");\\nconst callManager = new Fonoster.CallManager();\\n\\n// Few notes:\\n//  1. Update the from to look exactly as the Number you added \\n//  2. Use an active phone or mobile\\n//  3. Replace the webhook with the one from your Ngrok\\ncallManager.call({\\n from: \\"9842753574\\",\\n to: \\"17853178070\\",\\n webhook: \\"https://5a2d2ea5d84d.ngrok.io\\",\\n ignoreE164Validation: true\\n})\\n.then(console.log)\\n.catch(console.error);\\n```\\n\\nFinally, run your script with: `node call.js`\\n\\nIf everything goes well, you will start seeing the output in the console you are running your Voice Application. You will also receive a call that will stream a \\"Hello World,\\" which further confirms that everything is behaving as it should.\\n\\n![call_request](https://user-images.githubusercontent.com/80093500/193678241-8be38da0-cb54-4b25-a4d3-7842a94baa00.png)\\n\\n### Troubleshooting \\n\\n1. Are you not receiving the call at all?\\nThe first thing to check is that your SIP Service Provider configuration is correct. Next, double-check the `username`, `password`, and `host`. If your Provider has an Admin console, check if you can see the registration from Fonoster.\\n\\nNext, make sure the `from` matches the Number given to you by your Provider. \\nAlso, double-check the `to` has the correct prefix (for example, +1, etc.).\\n\\n2. You receive the call but immediately hang up (did not hear a sound)\\nFirst, verify that Ngrok is still running. Next, compare Ngrok\'s URL with the webhook on your Number. They both need to match!\\n\\nThen observe the console\'s output where your Voice Application is running, and see if there are any errors.\\n\\n#### Giving feedback to Team Fonoster\\nWe want to provide you with the best possible experience. To do that, we need your valuable feedback. Because we know you are busy, we provide two ways to get quick feedback from you. From the command line, use the `fonoster bug` command to start a GitHub issue. Or, you can use the `fonoster feedback` command to complete a short survey (which takes less than 30 seconds)."},{"id":"welcome","metadata":{"permalink":"/blog/welcome","editUrl":"https://github.com/fonoster/website/edit/main/docs/blog/blog/2021-12-01-welcome/index.md","source":"@site/blog/2021-12-01-welcome/index.md","title":"Welcome","description":"Welcome to Fonoster\'s blog section, if you want to contribute with a Tutorial or Guide let our team know via Discord,","date":"2021-12-01T00:00:00.000Z","formattedDate":"December 1, 2021","tags":[{"label":"fonoster","permalink":"/blog/tags/fonoster"},{"label":"voice","permalink":"/blog/tags/voice"}],"readingTime":0.13,"hasTruncateMarker":false,"authors":[{"name":"Pedro Sanders","title":"CTO at Fonoster","url":"https://github.com/psanders","imageURL":"https://github.com/psanders.png","key":"psanders"}],"frontMatter":{"slug":"welcome","title":"Welcome","authors":["psanders"],"tags":["fonoster","voice"]},"prevItem":{"title":"The essentials of building Voice Applications with Fonoster","permalink":"/blog/The essentials of building Voice Applications with Fonoster"}},"content":"Welcome to Fonoster\'s blog section, if you want to contribute with a Tutorial or Guide let our team know via [Discord](https://discord.gg/4QWgSz4hTC),\\nwe always welcome new contributors."}]}')}}]);