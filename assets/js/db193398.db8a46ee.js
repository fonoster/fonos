"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6988],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>g});var o=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,o,i=function(e,t){if(null==e)return{};var n,o,i={},r=Object.keys(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=o.createContext({}),c=function(e){var t=o.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},u=function(e){var t=c(e.components);return o.createElement(l.Provider,{value:t},e.children)},d="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},p=o.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),d=c(n),p=i,g=d["".concat(l,".").concat(p)]||d[p]||h[p]||r;return n?o.createElement(g,a(a({ref:t},u),{},{components:n})):o.createElement(g,a({ref:t},u))}));function g(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,a=new Array(r);a[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[d]="string"==typeof e?e:i,a[1]=s;for(var c=2;c<r;c++)a[c]=n[c];return o.createElement.apply(null,a)}return o.createElement.apply(null,n)}p.displayName="MDXCreateElement"},6379:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var o=n(7462),i=(n(7294),n(3905));const r={slug:"Steps for building conversational interfaces",title:"Steps for building conversational interfaces",authors:["yuricodes"],tags:["fonoster","voice","OSS"]},a="What is a Conversational User Interface",s={permalink:"/blog/Steps for building conversational interfaces",editUrl:"https://github.com/fonoster/website/edit/main/docs/blog/blog/2023-01-12-steps_for_creating_conversational_interfaces.md",source:"@site/blog/2023-01-12-steps_for_creating_conversational_interfaces.md",title:"Steps for building conversational interfaces",description:"A conversational user interface (CUI) is the way users interact with software through language-understanding interfaces, whether that\u2019s text or voice.",date:"2023-01-12T00:00:00.000Z",formattedDate:"January 12, 2023",tags:[{label:"fonoster",permalink:"/blog/tags/fonoster"},{label:"voice",permalink:"/blog/tags/voice"},{label:"OSS",permalink:"/blog/tags/oss"}],readingTime:4.47,hasTruncateMarker:!1,authors:[{name:"Yuri Santana",title:"Developer Relations Advocate at Fonoster",url:"https://github.com/yuricodes",imageURL:"https://github.com/yuricodes.png",key:"yuricodes"}],frontMatter:{slug:"Steps for building conversational interfaces",title:"Steps for building conversational interfaces",authors:["yuricodes"],tags:["fonoster","voice","OSS"]},prevItem:{title:"The way VUIs are reshaping human-device interactions",permalink:"/blog/The way VUIs are reshaping human-device interactions"},nextItem:{title:"Connect Fonoster to Dialogflow",permalink:"/blog/Connect Fonoster to Dialogflow"}},l={authorsImageUrls:[void 0]},c=[{value:"Product design",id:"product-design",level:2},{value:"Conversation structure",id:"conversation-structure",level:2},{value:"Interaction design",id:"interaction-design",level:2},{value:"Word design",id:"word-design",level:2},{value:"Personality design",id:"personality-design",level:2},{value:"Sound design",id:"sound-design",level:2},{value:"Prototype and testing",id:"prototype-and-testing",level:2},{value:"Metrics",id:"metrics",level:2}],u={toc:c},d="wrapper";function h(e){let{components:t,...n}=e;return(0,i.kt)(d,(0,o.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"A conversational user interface (CUI) is the way users interact with software through language-understanding interfaces, whether that\u2019s text or voice. "),(0,i.kt)("p",null,"It is formulated to emulate human interaction and that is reflected every step of the way. "),(0,i.kt)("p",null,"Prior to starting building your conversational interface, it\u2019s important to have several aspects pre-defined to make the development and design process more clear and direct. "),(0,i.kt)("h1",{id:"before-building-a-conversational-interface"},"Before building a conversational interface"),(0,i.kt)("p",null,"You will need to have a clear vision on the following aspects: "),(0,i.kt)("ul",null,(0,i.kt)("li",null," ",(0,i.kt)("strong",null," Type of interaction ")," "),"Is the user going to interact with the app using text? Using voice? or a mix of both? This will depend entirely on the needs your company has and the type of interaction your users need.",(0,i.kt)("li",null," ",(0,i.kt)("strong",null," Goal of interaction ")," "),"Is it transactional or relational? Do you want your users to buy something? This will completely shape the word and interaction design to fit the needs as appropriate.",(0,i.kt)("li",null," ",(0,i.kt)("strong",null," Domain of knowledge ")," "),"Is your app going to be  generalist? Would you be able to talk with it about anything or is it going to be a specialist? Focused on your product and specific topics surrounding it? This will not only limit and craft the development process but also help with the conversation design.",(0,i.kt)("li",null," ",(0,i.kt)("strong",null," Who takes the initiative ")," "),"Is it going to be proactive and lead the conversation or reactive and respond only when prompted by the user?",(0,i.kt)("li",null,(0,i.kt)("strong",null," Depth of conversation")," "),"Is it a single shift or a multi-turn conversation with the user?"),(0,i.kt)("h1",{id:"steps-for-creating-conversational-interfaces"},"Steps for creating conversational interfaces"),(0,i.kt)("h2",{id:"product-design"},"Product design"),(0,i.kt)("p",null,"It should involve the tech side, business knowledge and what your users need. "),(0,i.kt)("p",null,"Create a list of possible functionalities and eliminate, according to your already established goal of interaction, domain of knowledge and depth of conversation. Define those that will end as part of the minimum viable product (MVP)."),(0,i.kt)("h2",{id:"conversation-structure"},"Conversation structure"),(0,i.kt)("p",null,"This is the point where your team needs to start crafting the happy path your application will follow.\nYou will also need to define the order the information will be presented to the user after a keyword is identified from their input to trigger a search query into your database. "),(0,i.kt)("p",null,"To know more about conversation structure, check out Fonoster\u2019s video on ",(0,i.kt)("a",{parentName:"p",href:"https://youtu.be/ChqlotD4aDk"},"Conversational Interface Design")),(0,i.kt)("h2",{id:"interaction-design"},"Interaction design"),(0,i.kt)("p",null,"Much like conversation structure, your team will need to design how to solve each of the presented interactions on the Happy Path, presenting the user with several options or \u2018paths\u2019 they can trigger on the application that will take them to their desired outcome with no friction. "),(0,i.kt)("p",null,"For your application to learn, conversational patterns must be used to craft it based on the ideal interaction between the app and the user."),(0,i.kt)("h2",{id:"word-design"},"Word design"),(0,i.kt)("p",null,"Picking the exact words to provoke actions in your users is a science by itself. That\u2019s why it\u2019s important to choose specific words and sounds that will make the user reach the goal we want.  "),(0,i.kt)("p",null,"We can aid ourselves by asking open, closed or yes or no questions. Users have a better time responding to \u2018which country would you like to visit?\u2019 than to \u2018where do you want to go\u2019.  "),(0,i.kt)("h2",{id:"personality-design"},"Personality design"),(0,i.kt)("p",null,"This is where your team designs the aspects that define your assistant. Your team should be able to identify how the assistant will respond to specific circumstances and how it\u2019s never going to respond. "),(0,i.kt)("p",null,"This is usually where an avatar is created with the demographic characteristics of the assistant and the behavior is defined extensively. "),(0,i.kt)("h2",{id:"sound-design"},"Sound design"),(0,i.kt)("p",null,"It is now time to define the sound of your assistant. Is it going to be an automated voice or a voice actor? "),(0,i.kt)("p",null,"This also includes setting up the sound effects that will be played when opening or closing the assistant. "),(0,i.kt)("h1",{id:"after-building"},"After building"),(0,i.kt)("h2",{id:"prototype-and-testing"},"Prototype and testing"),(0,i.kt)("p",null,"Now that our conversational interface prototype is ready to be released to our users, it\u2019s important to keep on listening to feedback to see which features are working and which ones need to be polished or deleted. "),(0,i.kt)("p",null,"You can begin testing within your own team or community by reading the conversation structure out loud and noticing how they respond to certain choices or paths presented. Remember the goal is to simulate human to human interaction. This is called ",(0,i.kt)("strong",null," analog testing "),"."),(0,i.kt)("p",null,"You can also submit your conversation structure to a platform that will act as a user, allowing you to identify issues and corner cases. This is called ",(0,i.kt)("strong",null," automated testing. ")),(0,i.kt)("p",null,"Lastly, we have ",(0,i.kt)("strong",null," beta testing.")," It is done by taking a selected group of users and, making the application available for them to get feedback from  your own community before releasing it to a bigger audience. "),(0,i.kt)("h2",{id:"metrics"},"Metrics"),(0,i.kt)("p",null,"After you have made your application available to your users, one quick way to identify if it\u2019s working or which features are the ones they prefer is by analyzing metrics. "),(0,i.kt)("p",null,"This will allow you to know if the objective the user has set has been met by the application, help you correct interactions and questions and which utterances you should train your interface on. "),(0,i.kt)("p",null,"There are many software applications to know the metrics of both text and voice interfaces, they should give you a clear view of the users, recurrency, functionalities and where your users are abandoning your assistant."))}h.isMDXComponent=!0}}]);